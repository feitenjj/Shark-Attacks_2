# -*- coding: utf-8 -*-
"""Shark - Project - Team3 - Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p7kxqPzMbBucegZvLs6uPiJYHNu7Xr9j
"""

import pandas as pd

!pip install xlrd

df = pd.read_excel("https://www.sharkattackfile.net/spreadsheets/GSAF5.xls")

df.head()

# Count the number of null values in each column
df.isna().sum()

#Checking shape.
 df.shape #rows and columns

#Checking for duplicates.
df.duplicated().sum()

#Checking for duplicates.
df.duplicated()

df.duplicated().any()

#Converting Country column to uppercase.
df['Country'] = df['Country'].str.upper()
df

# Checking if USA is the only way the country was written, as we are going to work with USA
country_list = sorted([c for c in df['Country'].unique() if isinstance(c, str)])
print(country_list)

df.Country.value_counts()

df.Country.value_counts().sum()

# Filters the dataframe with only USA attacks.
usa_filtered_df = df[df['Country'].str.strip().str.upper() == "USA"]
usa_filtered_df

#Cleans the state names.
usa_filtered_df["State"] = usa_filtered_df["State"].str.replace(r'^"|"$', '', regex=True).str.strip()
usa_filtered_df["State"] = usa_filtered_df["State"].str.replace(r"\s*,\s*", '', regex=True).str.strip()
usa_filtered_df["State"]

#Cleans the activity names.
usa_filtered_df["Activity"] = usa_filtered_df["Activity"].str.replace(r'^"|"$', '', regex=True).str.strip()
usa_filtered_df["Activity"] = usa_filtered_df["Activity"].str.replace(r"\s*,\s*", '', regex=True).str.strip()
usa_filtered_df["Activity"]

#Cleans the location names.
usa_filtered_df["Location"] = usa_filtered_df["Location"].str.replace(r'^"|"$', '', regex=True).str.strip()
usa_filtered_df["Location"] = usa_filtered_df["Location"].str.replace(r"\s*,\s*", ', ', regex=True).str.strip()
usa_filtered_df["Location"]

#Resets the index numbers after cleaning rows.
usa_filtered_df.reset_index(drop=True, inplace=True)
usa_filtered_df

#Drops uneeded columns.
usa_filtered_df = usa_filtered_df.drop(columns=["Date", "Year", "Type", "Name", "Sex", "Age",	"Injury", "Time", "Fatal Y/N", "pdf", "Source", "href formula", "href", "Case Number", "Case Number.1", "original order", "Unnamed: 21", "Unnamed: 22"])
usa_filtered_df

#Drops uneeded columns.
usa_filtered_df = usa_filtered_df.drop(columns=["Species "])
usa_filtered_df

# Number of attacks per state in the USA.
usa_filtered_df.State.value_counts()

# Number of attacks per location.
usa_filtered_df.Location.value_counts()

# Number of attacks to surfing.
surf_count = df[df["Activity"] == "Surfing"].shape[0]
surf_count

# Filters the dataframe with only attacks to surfing.
surf_count_df = df[df["Activity"] == "Surfing"]
surf_count_df

# Number of attacks to surfing in the USA.
surf_count_usa = usa_filtered_df[usa_filtered_df["Activity"] == "Surfing"].shape[0]
surf_count_usa

#Percentage of attacks to the USA to surfing over the total number of attacks to surfing.
percentage_usa_surf = f"{((surf_count_usa/surf_count) * 100):.2f}%"
percentage_usa_surf

# Filters dataframe with only USA attacks to surfers.
usa_surf = usa_filtered_df[(usa_filtered_df["Country"] == "USA") & (usa_filtered_df["Activity"] == "Surfing")]
usa_surf

# Value counts the attacks in the USA to surfers per state.
usa_surf_states_value = usa_surf.State.value_counts()
usa_surf_states_value

type(usa_surf_states_value)

# Total attacks in Florida (all activities)
total_florida = df["State"].value_counts().get("Florida", 0)
# Total attacks in Florida when the activity was surfing
total_florida_surfing = df[
    (df["State"] == "Florida") &
    (df["Activity"] == "Surfing")
].shape[0]
# Percentage
if total_florida > 0:
    perc_surfing = (total_florida_surfing / total_florida) * 100
else:
    perc_surfing = 0

print(f"Number of attacks in Florida: {total_florida}")
print(f"Total attacks in Florida when the activity was surfing: {total_florida_surfing}")
print(f"Percentage of attacks in Florida when the activity was surfing over the total attacks in Florida: {perc_surfing:.2f}%")

# Filters dataframe with only Florida attacks to surfers.
florida_surf_df = usa_filtered_df[(usa_filtered_df["State"] == "Florida") & (usa_filtered_df["Activity"] == "Surfing")]
florida_surf_df

# Reset the index after filtering.
florida_surf_df.reset_index(drop=True, inplace=True)
florida_surf_df

# Value counts the attacks to surfers per Location in Florida.
florida_surf_series = florida_surf_df.Location.value_counts()
florida_surf_series

# Checking appearances of New Smyrna Beach in the various locations in Florida.
number_rows_new_smyrna = florida_surf_series.loc[florida_surf_series.index.str.contains("New Smyrna Beach", case=False, na=False)]
number_rows_new_smyrna

# Making a pattern of New Smyrna Beach in the various locations in Florida.
florida_surf_df["Location"] = florida_surf_df["Location"].replace({
   "Ponce Inlet, New Smyrna Beach, Volusia County": "New Smyrna Beach, Volusia County",
    "New Smyrna Beach": "New Smyrna Beach, Volusia County",
    "New Smyrna Beach / Waveland, Volusia County": "New Smyrna Beach, Volusia County",
    "South Jetty, New Smyrna Beach, Volusia County": "New Smyrna Beach, Volusia County",
    "New Smyrna Beach / Ponce Inlet, Volusia County": "New Smyrna Beach, Volusia County",
    "1.4 miles south of Ponce de Leon Jetty, New Smyrna Beach, Volusia County": "New Smyrna Beach, Volusia County",
    "Bethune Beach, south of New Smyrna Beach, Volusia County": "New Smyrna Beach, Volusia County",
    "South of Ponce Inlet, New Smyrna Beach, Volusia County": "New Smyrna Beach, Volusia County"
})

florida_surf_df["Location"]

#Counting attacks in New Smyrna Beach.
florida_surf_series = florida_surf_df.Location.value_counts()
florida_surf_series

usa_filtered_df = df[df['Country'].str.strip().str.upper() == "USA"]
usa_filtered_df

import seaborn as sns

# Get top 3 activities by attacks
top_activities = df['Activity'].value_counts().nlargest(3).index

# Filter dataframe
df_top_activities = df[df['Activity'].isin(top_activities)]

# Plot
sns.countplot(x='Activity', data=df_top_activities)

# Get top 3 countries by attacks when surfing
top_countries = surf_count_df['Country'].value_counts().nlargest(3).index

# Filter dataframe
surf_count_df_top = surf_count_df[surf_count_df['Country'].isin(top_countries)]

# Plot
sns.countplot(x='Country', data=surf_count_df_top)

# Get top 3 states by frequency when activity was surfing
top_usa_states_surf = usa_surf['State'].value_counts().nlargest(3).index

# Filter dataframe
df_top_states_surf = usa_surf[usa_surf['State'].isin(top_usa_states_surf)]

# Plot
sns.countplot(x='State', data=df_top_states_surf)

import matplotlib.pyplot as plt

# Get top 3 locations by frequency when activity was surfing
top_florida_locations_surf = florida_surf_df['Location'].value_counts().nlargest(3).index

# Filter dataframe
df_top_locations_surf = florida_surf_df[florida_surf_df['Location'].isin(top_florida_locations_surf)]

# Plot
sns.countplot(x='Location', data=df_top_locations_surf)
plt.xticks(rotation=45, ha='right')



